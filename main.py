from core.wake_word import listen_for_wake_word
from core.speech_to_text import transcribe
from core.intent_classifier import IntentClassifier
from core.router import SkillRouter
from core.tts import speak
from core.llm_engine import LLMEngine
from core.logger import setup_logger

logger = setup_logger(__name__)

def main():
    logger.info("\n[ğŸ§  JARVIS AI-PRO OFFLINE MODE]")
    logger.info("[ğŸ”„ Ready to activate via wake word...]")

    # Initialize core components
    intent_classifier = IntentClassifier()
    skill_router = SkillRouter()
    llm = LLMEngine().llm  # âœ… LLM engine (e.g., Ollama, GPT)

    while True:
        try:
            # ğŸ”Š Step 1: Wake word detection (blocking call)
            listen_for_wake_word()
            logger.info("[ğŸ¤] Wake word detected. Listening for your command...")

            # ğŸ™ï¸ Step 2: Speech to Text
            query = transcribe()
            if not query:
                continue
            logger.info(f"[ğŸ§] You said: {query}")

            # ğŸ§  Step 3: Predict Intent
            intent = intent_classifier.predict(query)
            logger.info(f"[ğŸ”] Predicted Intent: {intent}")

            # ğŸ› ï¸ Step 4: Route to Skill or fallback
            response = skill_router.route(intent, query)
            logger.info(f"[ğŸ¤–] Jarvis Response: {response}")

            # ğŸ§  Step 5: Fallback to LLM if no proper skill handled it
            if intent == "unknown" or "don't have a skill" in response.lower():
                logger.warning("[âš ï¸] No skill handled the intent. Falling back to LLM...")
                response = llm.invoke(query)

            # ğŸ—£ï¸ Step 6: Speak Response
            speak(response)

        except KeyboardInterrupt:
            logger.info("\n[âŒ] Terminated by user.")
            speak("Goodbye!")
            break

        except Exception as e:
            logger.exception(f"[âš ï¸] Unhandled exception occurred: {str(e)}")
            speak("Sorry, something went wrong.")

if __name__ == "__main__":
    main()
